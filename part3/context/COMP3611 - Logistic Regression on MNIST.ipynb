{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_qZU5gTltvP"
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Logistic Regression on MNIST</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Marc de Kamps and University of Leeds</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1soHIR4NltvS"
   },
   "source": [
    "## Logistic Regression on MNIST\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook is for exploration. It contains code snippets that you can reuse elsewhere. In particular it\n",
    "- Demonstrates how to obtain the MNIST dataset\n",
    "- Uses a PyTorch frontend for the MNIST dataset that allows easy access to each image and its classification\n",
    "- It demonstrates steepest gradient descent for the multiclass cross entropy loss function (something we will re-examine using PyTorch as a framework.\n",
    "\n",
    "This notebook is used in preparation for Activity 2.4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAkIwp6_ltvT"
   },
   "source": [
    "## MNIST data\n",
    "\n",
    "This is a first exploration of the MNIST dataset, which consists of a large collection of handwritten numerals, i.e images. The images are grey-scale $28 \\times 28$ pixels, and each image is associated with a label, which\n",
    "can take on any of the ten values, '0', '1', ..., '9', representing a human judgement about which numeral the image\n",
    "is supposed to represent.\n",
    "\n",
    "### Warning\n",
    "The first two lines in the following code are a hack after the disappearance of the original dataset website. It is a temporary fix. If you find the code block below doesn't work, contact the module leader. It will not be a major problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15625,
     "status": "ok",
     "timestamp": 1650552455133,
     "user": {
      "displayName": "Nishant Ravikumar",
      "userId": "05484258982955663074"
     },
     "user_tz": -60
    },
    "id": "Wxk0wjdgltvU",
    "outputId": "4f66594c-abe1-44d4-b35e-fb993923c82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepended http:// to 'www.di.ens.fr/~lelarge/MNIST.tar.gz'\n",
      "--2025-11-28 13:00:47--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2025-11-28 13:00:47--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz.1’\n",
      "\n",
      "MNIST.tar.gz.1          [      <=>           ]  33.20M  29.3MB/s    in 1.1s    \n",
      "\n",
      "2025-11-28 13:00:48 (29.3 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
      "\n",
      "x MNIST/\n",
      "x MNIST/raw/\n",
      "x MNIST/raw/train-labels-idx1-ubyte\n",
      "x MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "x MNIST/raw/t10k-labels-idx1-ubyte\n",
      "x MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "x MNIST/raw/train-images-idx3-ubyte\n",
      "x MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "x MNIST/raw/t10k-images-idx3-ubyte\n",
      "x MNIST/raw/train-images-idx3-ubyte.gz\n",
      "x MNIST/processed/\n",
      "x MNIST/processed/training.pt\n",
      "x MNIST/processed/test.pt\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mtar -zxvf MNIST.tar.gz\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[32m      7\u001b[39m transform=transforms.Compose([\n\u001b[32m      8\u001b[39m         transforms.ToTensor()\n\u001b[32m      9\u001b[39m         ])\n\u001b[32m     10\u001b[39m dataset1 = datasets.MNIST(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, train=\u001b[38;5;28;01mTrue\u001b[39;00m, download=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     11\u001b[39m                        transform=transform)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('.', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('.', train=False,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3nXB-iqltvV"
   },
   "source": [
    "The code does nothing but download the dataset and then transform it into a Pytorch native format, which is a Tensor. For practical purposes you can treat Tensor's as Numpy arrays for now. With that in mind, it is easy to inspect the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArEnh2MNltvW"
   },
   "outputs": [],
   "source": [
    "print(dataset1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPoPDFAmltvW"
   },
   "source": [
    "Careful inspection of the output of the print statement shows this is a (1,2) tensor, that is a single row of two elements. Let us first consider the second element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iHKuCL9jltvX"
   },
   "outputs": [],
   "source": [
    "print(dataset1[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMFBA9HMltvX"
   },
   "source": [
    "This is a single numeral. Possibly the label of the image, which then would be the first element. Let's explore this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib3ePz5PltvY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# in general you have to be careful in convering tensors to python arrays\n",
    "# a tensor in general will be created on the gpu, and will have some stuff that doesn't relate to the data, like\n",
    "# gradient information. First convert it to a cpu object, detach the data and then convert it to numpy arrays.\n",
    "np_arr = dataset1[0][0].to('cpu').detach().numpy()\n",
    "print(np_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGLNPdw5ltvY"
   },
   "source": [
    "It is tempting to try and run imshow directly on np_arr. It won't work and the shape information should give you a clue as to why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6FltdkaltvZ"
   },
   "outputs": [],
   "source": [
    "print(np_arr[0].shape)\n",
    "nr_pix =np_arr[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APZ9cj-2ltvZ"
   },
   "source": [
    "That should be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlzTTa9Hltva"
   },
   "outputs": [],
   "source": [
    "plt.imshow(np_arr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfU0KifPltva"
   },
   "source": [
    "That's better! Do the image and label match? Let's try a random other pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCzsasebltva"
   },
   "outputs": [],
   "source": [
    "print(dataset1[122][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Me2OOEEfltva"
   },
   "outputs": [],
   "source": [
    "plt.imshow(dataset1[122][0][0])\n",
    "plt.savefig('two.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OA2mGVYUltva"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "design=np.array([t[0].to('cpu').detach().numpy().flatten() for t in dataset1])\n",
    "labels=[t[1] for t in dataset1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNxdwXSjltvb"
   },
   "outputs": [],
   "source": [
    "print(design.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkrXxUynltvb"
   },
   "source": [
    "Are the rows indeed images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwHhuLWJltvb"
   },
   "outputs": [],
   "source": [
    "img22 = np.array(design[22]) # copy it\n",
    "img22.shape = nr_pix, nr_pix\n",
    "plt.imshow(img22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxE_R6Kltvb"
   },
   "source": [
    "Looks that way, so *design* is a design matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVKIJnS9ltvb"
   },
   "source": [
    "Convert the labels into target vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70n3k6SFltvc"
   },
   "outputs": [],
   "source": [
    "nr_classes = 10\n",
    "t=np.zeros(design.shape[0]*nr_classes)\n",
    "t.shape=design.shape[0],nr_classes\n",
    "\n",
    "for i,ind in enumerate(labels):\n",
    "    t[i][ind] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMZgI79qltvc"
   },
   "source": [
    "### Create the actual regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imqe3AERltvc"
   },
   "outputs": [],
   "source": [
    "# add a constant one to each pattern\n",
    "ones = np.ones(design.shape[0])\n",
    "ones.shape = design.shape[0],1\n",
    "designbias=np.concatenate((design,ones),axis=1)\n",
    "print(designbias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3DPHR-Kltvc"
   },
   "outputs": [],
   "source": [
    "# create the weights. A given image connects to 785 of a single node. There will be 10 nodes, one\n",
    "\n",
    "weights = np.random.normal(0.,1.,size=(nr_pix*nr_pix+1)*nr_classes)\n",
    "weights.shape = nr_pix*nr_pix + 1, nr_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb0Ixya0ltvc"
   },
   "source": [
    "The main text mentions a numerical issue that may crop up when implementing a naive implementation of softmax. Have a look at the stackoverflow discussion.\n",
    "\n",
    "The gradient is given in the main text by the following equation:\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w_j} = \\sum^N_{i=1}(y_{ij} - t_{ij}) \\boldsymbol{\\Phi}_i\n",
    "$$\n",
    "As you can see, with the help of *np.outer*, this line can be expressed very tersely in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPtq8C3zltvd"
   },
   "outputs": [],
   "source": [
    "# A suitable softmax implementation was taken from this discussion:\n",
    "# https://stackoverflow.com/questions/42599498/numercially-stable-softmax\n",
    "# (sic)\n",
    "\n",
    "\n",
    "\n",
    "def stableSoftmax(x):\n",
    "    z = x - np.max(x, axis=-1, keepdims=True)\n",
    "    numerator = np.exp(z)\n",
    "    denominator = np.sum(numerator, axis=-1, keepdims=True)\n",
    "    softmax = numerator / denominator\n",
    "    return softmax\n",
    "\n",
    "def update(designbias,weights):\n",
    "    return stableSoftmax(designbias.dot(weights))\n",
    "\n",
    "# The gradient is calculated over a single input pattern. This is a 10 \\time 785 matrix. To do this\n",
    "# over the entire dataset would require 60000 of them, which may lead to memory problems\n",
    "\n",
    "def gradient(target, weights, designbias,i):\n",
    "    ms=np.outer(designbias[i],update(designbias,weights)[i] - target[i])\n",
    "    return ms\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVJMMW25ltvd"
   },
   "source": [
    "### Evaluating our Regressor\n",
    "\n",
    "Before we do any training, let's evaluate the regressor on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrYqgqNwltvd"
   },
   "outputs": [],
   "source": [
    "designtest=np.array([t[0].to('cpu').detach().numpy().flatten() for t in dataset2])\n",
    "labelstest=np.array([t[1] for t in dataset2])\n",
    "print(labelstest.shape)\n",
    "ones = np.ones(designtest.shape[0])\n",
    "ones.shape = designtest.shape[0],1\n",
    "designbiastest=np.concatenate((designtest,ones),axis=1)\n",
    "\n",
    "def correctlyClassified(labels,designbias,weights):\n",
    "    outcomes=update(designbias,weights)\n",
    "    outcomelabels = np.array([ np.argmax(x) for x in outcomes ])\n",
    "    difftest = outcomelabels - labels\n",
    "    return np.count_nonzero(difftest==0),outcomes.shape[0]\n",
    "\n",
    "correctlyClassified(labelstest,designbiastest,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5g9t-jaltvd"
   },
   "source": [
    "We use a very crude measure: we count how many patterns were actually classified in agreement with their label. As you can see the results are approximately at chance level, as they should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWmTl1x6ltvd"
   },
   "outputs": [],
   "source": [
    "nrdatapoints=designbias.shape[0]\n",
    "r = 0.02\n",
    "for i in range(5000):\n",
    "    if i%1000 == 0: print(i)\n",
    "        \n",
    "    weights -= r*gradient(t, weights, designbias,np.random.randint(0,nrdatapoints-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3d6gCxHltvd"
   },
   "outputs": [],
   "source": [
    "correctlyClassified(labelstest,designbiastest,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGbOqjRDltve"
   },
   "source": [
    "After training things have considerably improved.  A proper analysis should be done with separation of test and training set and cross validation (see Machine Learning pipeline notebooks)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP5611M - Logistic Regression on MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
